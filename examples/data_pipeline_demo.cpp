#include <iostream>
#include <chrono>
#include "dlvk/data/mnist.h"
#include "dlvk/data/dataloader.h"
#include "dlvk/core/vulkan_device.h"

using namespace dlvk;

int main() {
    try {
        std::cout << "ðŸš€ DLVK Phase 6.1 - Data Infrastructure Demo" << std::endl;
        std::cout << "=============================================" << std::endl;

        // Initialize Vulkan device
        auto device = std::make_shared<VulkanDevice>();
        device->initialize();
        std::cout << "âœ… Vulkan device initialized" << std::endl;

        // Create MNIST dataset
        std::cout << "\nðŸ“ Loading MNIST Dataset..." << std::endl;

        // Load training and test datasets
        auto train_dataset = std::make_shared<data::MnistDataset>("./data/mnist", true, true);
        auto test_dataset = std::make_shared<data::MnistDataset>("./data/mnist", false, true);

        std::cout << "âœ… Training samples: " << train_dataset->size() << std::endl;
        std::cout << "âœ… Test samples: " << test_dataset->size() << std::endl;

        // Create data loaders
        std::cout << "\nðŸ”„ Creating Data Loaders..." << std::endl;
        data::DataLoader train_loader(train_dataset, device, 32, true, false);
        data::DataLoader test_loader(test_dataset, device, 32, false, false);

        std::cout << "âœ… Training batches: " << train_loader.num_batches() << std::endl;
        std::cout << "âœ… Test batches: " << test_loader.num_batches() << std::endl;

        // Test data loading performance
        std::cout << "\nâš¡ Testing Data Loading Performance..." << std::endl;
        auto start_time = std::chrono::high_resolution_clock::now();
        
        int batch_count = 0;
        for (size_t i = 0; i < std::min(10UL, train_loader.num_batches()); ++i) {
            auto [inputs, targets] = train_loader.get_batch(i);
            batch_count++;
            
            // Verify batch shapes
            std::cout << "  Batch " << i << ": Input shape [";
            for (size_t j = 0; j < inputs.shape().size(); ++j) {
                std::cout << inputs.shape()[j];
                if (j < inputs.shape().size() - 1) std::cout << ", ";
            }
            std::cout << "], Target shape [";
            for (size_t j = 0; j < targets.shape().size(); ++j) {
                std::cout << targets.shape()[j];
                if (j < targets.shape().size() - 1) std::cout << ", ";
            }
            std::cout << "]" << std::endl;
        }
        
        auto end_time = std::chrono::high_resolution_clock::now();
        auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end_time - start_time);
        
        std::cout << "âœ… Loaded " << batch_count << " batches in " << duration.count() << "ms" << std::endl;
        std::cout << "âœ… Average: " << (duration.count() / batch_count) << "ms per batch" << std::endl;

        // Test data shuffling
        std::cout << "\nðŸ”€ Testing Data Shuffling..." << std::endl;
        std::cout << "Before shuffle - First 3 sample indices from first batch:" << std::endl;
        
        // Get first batch
        auto [batch1_input, batch1_target] = train_loader.get_batch(0);
        
        // Download some target data to see labels
        std::vector<float> first_targets(batch1_target.shape()[0] * 10); // batch_size * num_classes
        batch1_target.download_data(first_targets.data());
        
        for (int i = 0; i < 3 && i < static_cast<int>(batch1_target.shape()[0]); ++i) {
            // Find the label (index of 1.0 in one-hot encoding)
            for (int j = 0; j < 10; ++j) {
                if (first_targets[i * 10 + j] > 0.5f) {
                    std::cout << "  Sample " << i << ": Label " << j << std::endl;
                    break;
                }
            }
        }
        
        // Shuffle and get again
        train_loader.new_epoch();
        auto [batch2_input, batch2_target] = train_loader.get_batch(0);
        
        std::vector<float> second_targets(batch2_target.shape()[0] * 10);
        batch2_target.download_data(second_targets.data());
        
        std::cout << "After shuffle - First 3 sample indices from first batch:" << std::endl;
        for (int i = 0; i < 3 && i < static_cast<int>(batch2_target.shape()[0]); ++i) {
            for (int j = 0; j < 10; ++j) {
                if (second_targets[i * 10 + j] > 0.5f) {
                    std::cout << "  Sample " << i << ": Label " << j << std::endl;
                    break;
                }
            }
        }

        // Test transforms (demonstration)
        std::cout << "\nðŸŽ¨ Data Transforms Architecture Ready:" << std::endl;
        std::cout << "âœ… Transform interface designed for extensibility" << std::endl;
        std::cout << "âœ… Compose pattern for chaining transformations" << std::endl;
        std::cout << "âœ… Factory functions for dataset-specific transforms" << std::endl;
        std::cout << "âœ… Ready for implementation in future updates" << std::endl;

        std::cout << "\nðŸŽ‰ Phase 6.1 Data Infrastructure Demo Complete!" << std::endl;
        std::cout << "=" << std::string(50, '=') << std::endl;
        std::cout << "âœ… MNIST dataset loading with synthetic fallback" << std::endl;
        std::cout << "âœ… Data transformation architecture designed and ready" << std::endl;
        std::cout << "âœ… Efficient batch processing with DataLoader" << std::endl;
        std::cout << "âœ… GPU tensor creation and data upload working" << std::endl;
        std::cout << "âœ… Data shuffling and epoch management implemented" << std::endl;
        std::cout << "âœ… Ready for integration with training pipeline" << std::endl;
        
    } catch (const std::exception& e) {
        std::cerr << "âŒ Error: " << e.what() << std::endl;
        return 1;
    }

    return 0;
}
